# Hacking AI: Easy As Pie!
Learn about AI hacking and utilize AI tools to hack!

## WiCyS Conference 2025 Workshop Materials

### Demo #1: Prompt Injection
- Gandalf by Lakera: https://gandalf.lakera.ai/gandalf

### Demo #2: AI Tools for Cyber
- Amazon PartyRock: https://partyrock.aws/home

### Demo #3: Offline AI Tools
- Ollama: https://ollama.com/
- Llama3 on Ollama setup guide: https://github.com/ollama/ollama

### Demo #4: Attacks on Web Chatbots
- https://portswigger.net/web-security/llm-attacks/lab-exploiting-llm-apis-with-excessive-agency

### Connect with the speaker:
- https://www.linkedin.com/in/betta-lyon-delsordo/
- https://lyondelsordobetta.wixsite.com/betta

## Full Reference Materials

Practice prompt injection:
- Gandalf by Lakera: https://gandalf.lakera.ai/gandalf
- Immersive Labs: https://prompting.ai.immersivelabs.com/ 
- Prompt Airlines by Wiz: https://promptairlines.com/
- Damn Vulnerable LLM Agent: https://github.com/WithSecureLabs/damn-vulnerable-llm-agent 

Prompt injection examples:
- https://github.com/mik0w/pallms
- https://github.com/Cranot/chatbot-injections-exploits
- https://github.com/TakSec/Prompt-Injection-Everywhere
- https://gist.github.com/coolaj86/6f4f7b30129b0251f61fa7baaa881516
- https://github.com/dair-ai/Prompt-Engineering-Guide/blob/main/guides/prompts-adversarial.md
- https://gist.github.com/deadbits/e93a90aa36c9aa7b5ce1179597a6fe3d

Practice attacks on web chatbots:
- https://portswigger.net/web-security/llm-attacks
- https://portswigger.net/web-security/llm-attacks/lab-exploiting-llm-apis-with-excessive-agency
- https://portswigger.net/web-security/llm-attacks/lab-exploiting-vulnerabilities-in-llm-apis
- https://portswigger.net/web-security/llm-attacks/lab-indirect-prompt-injection
- https://portswigger.net/web-security/llm-attacks/lab-exploiting-insecure-output-handling-in-llms 

AI for hacking:
- Amazon PartyRock: https://partyrock.aws/home
- Ollama: https://ollama.com/
- Llama3 on Ollama setup guide: https://github.com/ollama/ollama
- GPT4All: https://www.nomic.ai/gpt4all
- "Uncensored" models: https://erichartford.com/uncensored-models and https://ollama.com/library/llama2-uncensored
- https://github.com/GreyDGL/PentestGPT
- https://github.com/ipa-lab/hackingBuddyGPT

Certifications:
- https://secops.group/our-services/ai-ml-pentest/
- https://learn.deeplearning.ai/courses/red-teaming-llm-applications/lesson/t1tp1/introduction?courseName=red-teaming-llm-applications
- https://academy.hackthebox.com/path/preview/ai-red-teamer
- https://aws.amazon.com/certification/certified-ai-practitioner/

Further reading:
- https://lakera-marketing-public.s3.eu-west-1.amazonaws.com/Lakera%2BAI%2B-%2BReal%2BWorld%2BLLM%2BExploits%2B(Jan%2B2024)-min.pdf
- https://wiki.offsecml.com/Welcome+to+the+Offensive+ML+Playbook
- https://platform.dreadnode.io/
- https://www.blazeinfosec.com/post/llm-pentest-agent-hacking/
- https://learnprompting.org/docs/prompt_hacking/injection
- https://llmsecurity.net/
- https://genai.owasp.org/
- https://aivillage.org/large%20language%20models/threat-modeling-llm/
- https://github.com/ScottLogic/prompt-injection
- https://github.com/greshake/llm-security
- https://github.com/Hannibal046/Awesome-LLM
- https://github.com/ottosulin/awesome-ai-security
- https://atlas.mitre.org/matrices/ATLAS/
- https://github.com/EasyJailbreak/EasyJailbreak



